{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782353b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "pkdarabi_diagnosis_of_diabetic_retinopathy_path = kagglehub.dataset_download('pkdarabi/diagnosis-of-diabetic-retinopathy')\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c38bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"d:/Projects/Diabetic Retinopathy/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Import essential libreries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn as nn\n",
    "from torchvision import utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torch import optim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transformation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((255,255)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n",
    "   ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb2daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define object of the Train, Validation, and Test dataset.\n",
    "train_set = torchvision.datasets.ImageFolder('/root/.cache/kagglehub/datasets/pkdarabi/diagnosis-of-diabetic-retinopathy/versions/2/retino/train', transform=transform)\n",
    "train_set.transform\n",
    "val_set = torchvision.datasets.ImageFolder('/root/.cache/kagglehub/datasets/pkdarabi/diagnosis-of-diabetic-retinopathy/versions/2/retino/valid', transform=transform)\n",
    "val_set.transform\n",
    "test_set = torchvision.datasets.ImageFolder('/root/.cache/kagglehub/datasets/pkdarabi/diagnosis-of-diabetic-retinopathy/versions/2/retino/test', transform=transform)\n",
    "test_set.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4db21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing some images from Trainset\n",
    "CLA_label = {\n",
    "        0 : 'DR',\n",
    "        1 : 'No_DR',\n",
    "}\n",
    "figure = plt.figure(figsize=(10, 10))\n",
    "cols, rows = 4, 4\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "    img, label = train_set[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(CLA_label[label])\n",
    "    plt.axis(\"off\")\n",
    "    img_np = img.numpy().transpose((1, 2, 0))\n",
    "    # Clip pixel values to [0, 1]\n",
    "    img_valid_range = np.clip(img_np, 0, 1)\n",
    "    plt.imshow(img_valid_range)\n",
    "    plt.suptitle('Retinopathy Images', y=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda15a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and load Train, Validation and Test set\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shape of Dataset\n",
    "for key, value in {'Training data': train_loader, \"Validation data\": val_loader}.items():\n",
    "    for X, y in value:\n",
    "        print(f\"{key}:\")\n",
    "        print(f\"Shape of X : {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape} {y.dtype}\\n\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b786c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function can be useful in determining the output size of a convolutional layer,\n",
    "given the input dimensions and the convolutional layer's parameters.'''\n",
    "\n",
    "def findConv2dOutShape(hin,win,conv,pool=2):\n",
    "    kernel_size = conv.kernel_size\n",
    "    stride=conv.stride\n",
    "    padding=conv.padding\n",
    "    dilation=conv.dilation\n",
    "\n",
    "    hout=np.floor((hin+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    wout=np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "\n",
    "    if pool:\n",
    "        hout/=pool\n",
    "        wout/=pool\n",
    "    return int(hout),int(wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e2c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Architecture For Retinopathy Model\n",
    "class CNN_Retino(nn.Module):\n",
    "\n",
    "    def __init__(self, params):\n",
    "\n",
    "        super(CNN_Retino, self).__init__()\n",
    "\n",
    "        Cin,Hin,Win = params[\"shape_in\"]\n",
    "        init_f = params[\"initial_filters\"]\n",
    "        num_fc1 = params[\"num_fc1\"]\n",
    "        num_classes = params[\"num_classes\"]\n",
    "        self.dropout_rate = params[\"dropout_rate\"]\n",
    "\n",
    "        # CNN Layers\n",
    "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(Hin,Win,self.conv1)\n",
    "        self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv2)\n",
    "        self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv3)\n",
    "        self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv4)\n",
    "\n",
    "        # compute the flatten size\n",
    "        self.num_flatten=h*w*8*init_f\n",
    "        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
    "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
    "\n",
    "    def forward(self,X):\n",
    "\n",
    "        X = F.relu(self.conv1(X));\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv4(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, self.num_flatten)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.dropout(X, self.dropout_rate)\n",
    "        X = self.fc2(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72edb22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_model={\n",
    "        \"shape_in\": (3,255,255),\n",
    "        \"initial_filters\": 8,\n",
    "        \"num_fc1\": 100,\n",
    "        \"dropout_rate\": 0.15,\n",
    "        \"num_classes\": 2}\n",
    "\n",
    "# Create instantiation of Network class\n",
    "Retino_model = CNN_Retino(params_model)\n",
    "\n",
    "# define computation hardware approach (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "Retino_model = Retino_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bedec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary for CNN_Retino\n",
    "summary(Retino_model, input_size=(3, 255, 255),device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f96745",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"d:/Projects/Diabetic Retinopathy/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "loss_func = nn.NLLLoss(reduction=\"sum\")\n",
    "\n",
    "\n",
    "opt = optim.Adam(Retino_model.parameters(), lr=1e-4)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the learning rate\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "# Function to compute the loss value per batch of data\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "\n",
    "    loss = loss_func(output, target) # get loss\n",
    "    pred = output.argmax(dim=1, keepdim=True) # Get Output Class\n",
    "    metric_b=pred.eq(target.view_as(pred)).sum().item() # get performance metric\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b\n",
    "\n",
    "# Compute the loss value & performance metric for the entire dataset (epoch)\n",
    "def loss_epoch(model,loss_func,dataset_dl,opt=None):\n",
    "\n",
    "    run_loss=0.0\n",
    "    t_metric=0.0\n",
    "    len_data=len(dataset_dl.dataset)\n",
    "\n",
    "    # internal loop over dataset\n",
    "    for xb, yb in dataset_dl:\n",
    "        # move batch to device\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        output=model(xb) # get model output\n",
    "        loss_b,metric_b=loss_batch(loss_func, output, yb, opt) # get loss per batch\n",
    "        run_loss+=loss_b        # update running loss\n",
    "\n",
    "        if metric_b is not None: # update running metric\n",
    "            t_metric+=metric_b\n",
    "\n",
    "    loss=run_loss/float(len_data)  # average loss value\n",
    "    metric=t_metric/float(len_data) # average metric value\n",
    "\n",
    "    return loss, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define various parameters used for training and evaluation of a cnn_model\n",
    "\n",
    "params_train={\n",
    " \"train\": train_loader,\"val\": val_loader,\n",
    " \"epochs\": 60,\n",
    " \"optimiser\": optim.Adam(Retino_model.parameters(),lr=1e-4),\n",
    " \"lr_change\": ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20),\n",
    " \"f_loss\": nn.NLLLoss(reduction=\"sum\"),\n",
    " \"weight_path\": \"weights.pt\",\n",
    "}\n",
    "\n",
    "# train and validate the model\n",
    "model,loss_hist_m,metric_hist_m = train_val(Retino_model,params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38837d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence History Plot\n",
    "epochs=params_train[\"epochs\"]\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist_m[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist_m[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist_m[\"train\"],ax=ax[1],label='Acc_hist[\"train\"]')\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist_m[\"val\"],ax=ax[1],label='Acc_hist[\"val\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10885e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function For Classification Report\n",
    "def ture_and_pred_data(val_loader, model):\n",
    "    i = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.numpy()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "\n",
    "        y_true = np.append(y_true, labels)\n",
    "        y_pred = np.append(y_pred, pred)\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report for Retinopathy Classification Model based on Train Set\n",
    "y_true, y_pred = ture_and_pred_data(train_loader, Retino_model)\n",
    "print(classification_report(y_true, y_pred), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa117da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classification Report for Retinopathy Classification Model based on Validation Set\n",
    "y_true, y_pred = ture_and_pred_data(val_loader, Retino_model)\n",
    "print(classification_report(y_true, y_pred), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eccea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Retino_model, \"Retino_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e181f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "model = torch.load(\"Retino_model.pt\", weights_only=False)\n",
    "\n",
    "# Move the model to the GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Iterate over the test loader for prediction\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "\n",
    "        images = images.to(device)\n",
    "        output = model(images)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        predicted_classes = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "        for predicted_class in predicted_classes:\n",
    "            print(\"Predicted class:\", predicted_class.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edd7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification Report for Retinopathy Classification Model based on Test set\n",
    "y_true, y_pred = ture_and_pred_data(test_loader, model)\n",
    "print(classification_report(y_true, y_pred), '\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
